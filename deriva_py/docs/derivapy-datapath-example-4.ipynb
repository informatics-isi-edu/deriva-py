{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DataPath Example 4\n",
    "\n",
    "This notebook covers somewhat more advanced examples for using `DataPath`s. It assumes that you understand \n",
    "the concepts presented in the previous example notebooks.\n",
    "\n",
    "You should also read the ERMrest documentation and the derivapy wiki. There are more advanced concepts in this notebook that are demonstrated but not fully (re)explained here, as the concepts are explained in other documentation.\n",
    "\n",
    "## Exampe Data Model\n",
    "The examples require that you understand a little bit about the example catalog data model, which is based on the FaceBase project.\n",
    "\n",
    "### Key tables\n",
    "- `'dataset'` : represents a unit of data usually a `'study'` or `'experiment'`\n",
    "- `'sample'` : a biosample\n",
    "- `'assay'` : a bioassay (typically RNA-seq or ChIP-seq assays)\n",
    "\n",
    "### Relationships\n",
    "- `dataset <- sample`: A dataset may have one to many samples. I.e., there \n",
    "  is a foreign key reference from sample to dataset.\n",
    "- `sample <- assay`: A sample may have one to many assays. I.e., there is a\n",
    "  foreign key reference from assay to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import deriva modules\n",
    "from deriva_common import ErmrestCatalog, get_credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect with the deriva catalog\n",
    "protocol = 'https'\n",
    "hostname = 'www.facebase.org'\n",
    "catalog_number = 1\n",
    "credential = None\n",
    "# If you need to authenticate, use Deriva Auth agent and get the credential\n",
    "# credential = get_credential(hostname)\n",
    "catalog = ErmrestCatalog(protocol, hostname, catalog_number, credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the path builder interface for this catalog\n",
    "pb = catalog.getPathBuilder()\n",
    "\n",
    "# Get some local variable handles to tables for convenience\n",
    "dataset = pb.isa.dataset\n",
    "sample = pb.isa.sample\n",
    "assay = pb.isa.assay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit DataPaths\n",
    "**Proceed with caution**\n",
    "\n",
    "For compactness, `Table` objects (and `TableAlias` objects) provide `DataPath`-like methods. E.g., `link(...)`, `filter(...)`, and `entities(...)`, which will implicitly create `DataPath`s rooted at the table and return the newly created path. These operations `return` the new `DataPath` rather than mutating the `Table` (or `TableAlias`) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = dataset.filter(dataset.status > 2).entities()\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataPath-like methods\n",
    "The `DataPath`-like methods on `Table`s are essentially \"wrapper\" functions over the implicitly generated `DataPath` rooted at the `Table` instance. The wrappers include:\n",
    "- `link(...)` generates a path, links the related table, and returns the generated path.\n",
    "- `filter(...)` generate a path, adds a filter, and returns the generated path.\n",
    "- `entities(...)` generate a path, (optionally) selects columns, and returns an entity set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: selecting all columns of a table instance\n",
    "Passing a table (or table instance) object to the `entities(...)` method will project all (i.e., `*`) of its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "https://www.facebase.org/ermrest/catalog/1/entity/D:=isa:dataset/sample:=isa:sample/assay:=isa:assay\n"
     ]
    }
   ],
   "source": [
    "path = dataset.alias('D').path\n",
    "path.link(sample).link(assay)\n",
    "entities = path.entities()\n",
    "print(len(entities))\n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.facebase.org/ermrest/catalog/1/attribute/D:=isa:dataset/sample:=isa:sample/assay:=isa:assay/D:*\n"
     ]
    }
   ],
   "source": [
    "entities = path.entities(path.D)\n",
    "print(entities.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to remember that the entities method returns a entity set based on the entity type of the last elmenent of the path. In this example that means the number of results will be determined by the number of unique rows in the assay table instance in the path created above, as the last link method used the assay table.  \n",
    "\n",
    "In this example, we are only using attributes from dataset.  What this means is that even though the result of an entities method is always a entity set, since we are not including the attributes from assay in our result, it is possible that we may have duplicate rows, if the same assay is used in more then one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: selecting from multiple table instances\n",
    "More than one table instance may be selected in this manner and it can be mixed and matched with columns from other tables instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "https://www.facebase.org/ermrest/catalog/1/attribute/D:=isa:dataset/sample:=isa:sample/assay:=isa:assay/D:*,assay:fragmentation_method,sample:*,assay:isolation_protocol\n"
     ]
    }
   ],
   "source": [
    "entities = path.entities(path.D,\n",
    "                         path.assay.fragmentation_method,\n",
    "                         path.sample,\n",
    "                         path.assay.isolation_protocol)\n",
    "print (len(entities))\n",
    "print(entities.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you want to base the results on a different entity, you can introduce a table instance alias into the end of the path, before calling the entities function.  In this case, even though we are asking for the same attributes, we are getting the set of datasets, not the set of assays.  Also, since we are including the attributes from dataset in our query, we know that we will not be seeing any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "https://www.facebase.org/ermrest/catalog/1/attribute/D:=isa:dataset/sample:=isa:sample/assay:=isa:assay/$D/D:*,assay:fragmentation_method,sample:*,assay:isolation_protocol\n"
     ]
    }
   ],
   "source": [
    "entities = path.D.entities(path.D,\n",
    "                           path.assay.fragmentation_method,\n",
    "                           path.sample,\n",
    "                           path.assay.isolation_protocol)\n",
    "print (len(entities))\n",
    "print(entities.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Examples\n",
    "\n",
    "### Example: filters with logical operators\n",
    "This example shows how to combine two comparisons with a conjuncting (i.e., `and` operator). Because Python's logical-and (`and`) keyword cannot be overloaded, we instead overload the bitwise-and (`&`) operator. This approach has become customary among many similar data access libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataset.link(sample).link(assay).filter(\n",
    "    ((assay.sample_type == 'ChIP-seq') & (assay.selection == 'H3K27AC')))\n",
    "\n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.entities().dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: combine conjunction and disjunctions in filters\n",
    "Similar to the prior example, the filters allow combining of conjunctive and disjunctive operators. Like the bitwise-and operator, we also overload the bitwise-or (` | `) operator because the logical-or (`or`) operatar cannot be overloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataset.link(sample).link(assay).filter(\n",
    "    ((assay.sample_type == 'ChIP-seq') & (assay.selection == 'H3K27AC')) |\n",
    "    ((assay.sample_type == 'Input') & (assay.selection == 'genomicDNA')))\n",
    "\n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.entities().dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: filtering at different stages of the path\n",
    "Filtering a path does not have to be done at the end of a path. In fact, the initial intention of the ERMrest URI was to mimick \"RESTful\" semantics where a RESTful \"resource\" is identified, then filtered, then a \"sub-resource\" is identified, and then filtered, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataset.filter(dataset.release_date >= '2017-01-01') \\\n",
    "    .link(sample).filter(sample.species == 2) \\\n",
    "    .link(assay).filter(assay.selection == 'totalRNA')\n",
    "    \n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.entities().dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Examples\n",
    "\n",
    "### Example: explicit column links\n",
    "Up until now, the examples have shown how to link entities via _implicit_ join predicates. That is, we knew there existed a foriegn key reference constraint between foreign keys of one entity and keys of another entity. We needed only to ask ERMrest to link the entities in order to get the linked set.\n",
    "\n",
    "The problem with implicit links is that it become _ambiguous_ if there are more than one foreign key reference between tables. To support these situations, ERMrest and the `DataPath`'s `link(...)` method can specify the columns to use for the link condition, explicitly.\n",
    "\n",
    "The structure of the `on` clause is:\n",
    "- an equality comparison operation where\n",
    "- the _left_ operand is a column of the _left_ table instance which is also the path _context_ before the link method is called, and\n",
    "- the _right_ operand is a column of the _right_ table instance which is the table _to be linked_ to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataset.link(sample, on=(dataset.id==sample.dataset))\n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** Not all tables are related by foreign key references. ERMrest does not allow arbitrary relational joins. Tables must be related by a foreign key reference in order to link them in a data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.entities().fetch(limit=3).dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: explicit column links combined with table aliasing\n",
    "As usual, table instances are generated automatically unless we provide a table alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataset.link(sample.alias('S'), on=(dataset.id==sample.dataset))\n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we cannot use the alias right away in the `on` clause because it was not _bound_ to the path until _after_ the `link(...)` operation was performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: links with \"outer join\" semantics\n",
    "Up until now, the examples have shown \"`link`s\" with _inner join_ semantics. _Outer join_ semantics can be expressed as part of explicit column links, and _only_ when using explicit column links.\n",
    "\n",
    "The `link(...)` method accepts a \"`join_type`\" parameter, i.e., \"`.link(... join_type=TYPE)`\", where _TYPE_ may be `'left'`, `'right'`, `'full'`, and defaults to `''` which indicates inner join type.\n",
    "\n",
    "By '`right`' outer joining in the link from `'sample'` to `'dataset`', the following path gives us a reference to `'dataset'` entities that _may or may not_ have any samples with assays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = assay.link(sample.alias('S'), on=assay.sample==sample.id) \\\n",
    "            .link(dataset.alias('D'), sample.dataset==dataset.id, join_type='right')\n",
    "\n",
    "# path instances were not bound until the above line was executed\n",
    "\n",
    "entities = path.entities(path.D.accession, path.D.title, path.S.species, path.S.stage)\n",
    "\n",
    "print(entities.uri)\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that we have a full set of datasets _whether or not_ they have any samples with assays. For further evidence, we can convert to a DataFrame and look at a slice of its entries. Note that the sample's 'species' and 'stage' attributes do not exist for some entities (i.e., `NaN`) because those entities did not exist for the join condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.dataframe[700:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faceting Examples\n",
    "You may have noticed that in the examples above, the 'species' and 'stage' attributes are numeric. These are internal \"primary keys\" that are not meaningful and difficult to filter on. We may want to construct filters on our datasets based on these categories. This can be used for \"faceted search\" modes and can be useful even within the context of programmatic access to data in the catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: faceting on \"related\" tables\n",
    "Let's say we want to find all of the samples in our catalog where their species are 'Mus musculus' and their age stage are 'E10.5'.\n",
    "\n",
    "We need to extend our understanding of the data model with the following tables that are related to '`sample`'.\n",
    "- `isa.sample.species -> vocabulary.species.id`: the sample table has a foreign key reference to the '`species`' table.\n",
    "- `isa.sample.stage -> vocabulary.stage.id`: the sample table has a foreign key reference to the '`stage`' table.\n",
    "\n",
    "We may say that `species` and `stage` are _related_ to the `sample` table in the sense that `sample` has a direct foreign key relationship from it to them.\n",
    "\n",
    "For convenience, we will get local variables for the species and stage tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species = pb.vocabulary.species\n",
    "stage = pb.vocabulary.stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's link samples with species and filter on the term \"Mus musculus\" (i.e., \"mouse\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = sample.alias('S').link(species).filter(species.term == 'Mus musculus')\n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the _context_ of the path is the `species` table instance, but we need to link from the `sample` to the age `stage` table.\n",
    "\n",
    "To do so, we reference the `sample` table instance, in this case using its alias `S`. Then we link off of that table instance which updates the `path` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.S.link(stage).filter(stage.term == 'E10.5')\n",
    "print(path.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the path _context_ is the age `stage` table instance, but we wanted to get the entities for the `sample` table. To do so, again we will reference the `sample` table instance by the alias `S` we used. From there, we will call the `entities(...)` method to get the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = path.S.entities(path.S.id,\n",
    "                           path.S.collection_date,\n",
    "                           species=path.species.term,\n",
    "                           species_iri=path.species.iri,\n",
    "                           stage=path.stage.term,\n",
    "                           stage_iei=path.stage.iri)\n",
    "print(entities.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
